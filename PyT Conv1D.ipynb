{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc30654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c2ae6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292980, 447)\n"
     ]
    }
   ],
   "source": [
    "Concatnated = pd.read_csv('Concatnated.csv')    #.set_index('Time')\n",
    "Concatnated = np.array(Concatnated[:292980], dtype=np.float32)\n",
    "#Concatnated = torch.from_numpy(Concatnated)\n",
    "print(Concatnated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88c6da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CreatData = []\n",
    "X = Concatnated[:, :446]\n",
    "y = Concatnated[:,446]\n",
    "strat_time = 0\n",
    "timestamp = 10\n",
    "length = len(Concatnated)\n",
    "\n",
    "for i in range(int(abs(length/10-1))):\n",
    "    CreatData.append((X[strat_time:timestamp, :446], y[timestamp]))\n",
    "\n",
    "    strat_time = strat_time + 10\n",
    "    timestamp = timestamp + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eda5cc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.0301287e+00, 2.0545425e+01, 2.3036230e+01, ..., 4.0419906e-04,\n",
       "         1.1364905e-04, 5.6682518e-03],\n",
       "        [6.0662766e+00, 4.1093773e+01, 4.6072437e+01, ..., 8.1914989e-04,\n",
       "         2.2856677e-04, 1.1336603e-02],\n",
       "        [6.0843334e+00, 4.1102531e+01, 4.6072365e+01, ..., 8.5140375e-04,\n",
       "         2.3237262e-04, 1.1336901e-02],\n",
       "        ...,\n",
       "        [6.3550611e+00, 4.1233990e+01, 4.6071308e+01, ..., 1.3349598e-03,\n",
       "         2.8943276e-04, 1.1341364e-02],\n",
       "        [6.4452510e+00, 4.1277821e+01, 4.6070957e+01, ..., 1.4960399e-03,\n",
       "         3.0844129e-04, 1.1342849e-02],\n",
       "        [6.5474334e+00, 4.1327507e+01, 4.6070553e+01, ..., 1.6785341e-03,\n",
       "         3.2997734e-04, 1.1344530e-02]], dtype=float32),\n",
       " 0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CreatData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "025bf800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Sequences:  23437\n",
      "Number of Testing Sequences:  5860\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = train_test_split(CreatData, test_size=0.2)\n",
    "print(\"Number of Training Sequences: \", len(train_dataset))\n",
    "print(\"Number of Testing Sequences: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61d79d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1b59178",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('Normal', 'Fuzz', 'DoS', 'Replay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc15dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 446])\n",
      "2\n",
      "torch.Size([64, 10, 446])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "sets, labels = dataiter.next()\n",
    "\n",
    "print(sets[0].shape)\n",
    "print(sets[0].ndim)\n",
    "\n",
    "print(sets.shape)\n",
    "print(sets.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83529f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88f16345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m = nn.Conv1d(16, 33, 3, stride=2)\\ninput = torch.randn(20, 16, 50)\\noutput = m(input)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "425e7a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 50])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(20, 16, 50)\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea1643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94dd0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(10, 128, 5)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(128, 4, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4*108, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 128, 442 -> n, 128, 221\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 4, 217 -> n, 4, 108 \n",
    "        x = x.view(-1, 4*108)            # -> n, 400\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a26c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "sets = sets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d3e996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 128, 442])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1 = model.conv1(sets)\n",
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "547ada30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 4, 438])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2 = model.conv2(output1)\n",
    "output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48d5df85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 4, 219])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.pool(output2)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95cf3601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 5])\n",
      "torch.Size([4, 128, 5])\n",
      "torch.Size([120, 4])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv1d(10, 128, 5)\n",
    "print(conv1.weight.shape)\n",
    "\n",
    "conv2 = nn.Conv1d(128, 4, 5)\n",
    "print(conv2.weight.shape)\n",
    "\n",
    "fc1 = nn.Linear(4, 120)\n",
    "print(fc1.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb879d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5219933f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/367], Loss: nan\n",
      "Epoch [1/5], Step [200/367], Loss: nan\n",
      "Epoch [1/5], Step [300/367], Loss: nan\n",
      "Epoch [2/5], Step [100/367], Loss: nan\n",
      "Epoch [2/5], Step [200/367], Loss: nan\n",
      "Epoch [2/5], Step [300/367], Loss: nan\n",
      "Epoch [3/5], Step [100/367], Loss: nan\n",
      "Epoch [3/5], Step [200/367], Loss: nan\n",
      "Epoch [3/5], Step [300/367], Loss: nan\n",
      "Epoch [4/5], Step [100/367], Loss: nan\n",
      "Epoch [4/5], Step [200/367], Loss: nan\n",
      "Epoch [4/5], Step [300/367], Loss: nan\n",
      "Epoch [5/5], Step [100/367], Loss: nan\n",
      "Epoch [5/5], Step [200/367], Loss: nan\n",
      "Epoch [5/5], Step [300/367], Loss: nan\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (sets, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        #print(sets.shape)\n",
    "        sets = sets.to(device)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(sets)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52d59479",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cnn.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a5ab994",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53e1d83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07c187c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9184\\3389149184.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mn_class_correct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mn_class_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_correct\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(4)]\n",
    "    n_class_samples = [0 for i in range(4)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d3c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
