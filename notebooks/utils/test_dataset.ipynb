{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CANDataset(Dataset):\n",
    "    def __init__(self, root_dir, is_train=True, transform=None):\n",
    "        self.root_dir = Path(root_dir) / ('train' if is_train else 'val')\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        self.total_size = len(os.listdir(self.root_dir))\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        filename = f'{idx}.npz'\n",
    "        filename = self.root_dir / filename\n",
    "        data = np.load(filename)\n",
    "        X, y = data['X'], data['y']\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        X_tensor = torch.unsqueeze(X_tensor, dim=0)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "        if self.transform:\n",
    "            X_tensor = self.transform(X_tensor)\n",
    "        return X_tensor, y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in tqdm.tqdm(dataloader):\n",
    "        this_batch_size = data.size()[0]\n",
    "        weight = this_batch_size / dataloader.batch_size\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += weight * torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += weight * torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += weight\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_name='mexh'\n",
    "# data_dir = f'../Data/CHD_w29_s14_ID_Data/wavelet/{wavelet_name}/1/'\n",
    "data_dir = '../../../Data/LISA/Federated_Data/Preprocessed_Data/Kia/1/'\n",
    "train_dataset = CANDataset(root_dir=data_dir, is_train=True,)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128,\n",
    "    shuffle=True, pin_memory=True, sampler=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 29, 29]), torch.Size([128]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(train_dataloader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1619/1619 [02:34<00:00, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  tensor([1712.4263,  141.0008,  110.5848,   97.2896,  188.9378,  124.5931,\n",
      "         148.5182,   63.2015,  130.0784])\n",
      "Std:  tensor([1107.1625,  105.1148,   78.9460,   79.3443,  147.8017,   93.7031,\n",
      "         105.8413,   63.6263,  118.1454])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "means, stds = get_mean_and_std(train_dataloader)\n",
    "print('Mean: ', means)\n",
    "print('Std: ', stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data/CHD_w29_s14_ID_Data/1/'\n",
    "transform = transforms.Normalize(\n",
    "                            mean=(126.8058,  10.4403,   8.1874,   7.2068,  13.9896,   9.2265,  10.9938, 4.6789, 9.6320), \n",
    "                            std =(510.3837,  67.7702,  43.0419,  53.2845,  79.1804,  60.3768,  60.1881, 48.7489,  70.4148))\n",
    "train_dataset = CANDataset(root_dir=data_dir, is_train=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128,\n",
    "    shuffle=True, num_workers=8, \n",
    "    pin_memory=True, sampler=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../Data/CHD_w29_s14_ID_Data/1/train/1.npz'\n",
    "data = np.load(filename)\n",
    "X, y = data['X'], data['y']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a29cc2c05d3ee8d935820ad86792723c958d8c7f217aee9aa88e38f878a5d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
