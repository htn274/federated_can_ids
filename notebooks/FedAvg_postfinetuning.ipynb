{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../src/'))\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.central_ids import IDS\n",
    "from src.utils import cal_metric, print_results\n",
    "from src.dataset import CANDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pickle\n",
    "import torch\n",
    "from flwr.common.parameter import parameters_to_ndarrays\n",
    "from collections import OrderedDict\n",
    "from utils import set_parameters, test_model\n",
    "\n",
    "from pytorch_lightning import loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model = 'Kia'\n",
    "args = {\n",
    "    'data_dir': f'../../Data/LISA/{car_model}/1/',\n",
    "    'save_dir': f'../save/FedAvg_FN/{car_model}/',\n",
    "    'C': 2,\n",
    "    'B': 128,\n",
    "    'epochs': 5,\n",
    "    'val_freq': 1,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = 40\n",
    "ckpt_file = f'../save/federated/ckpt-rnd{rnd}.npz'\n",
    "tensors = np.load(ckpt_file, allow_pickle=True)['arr_0'][()]\n",
    "data_dir = f'../../Data/LISA/{car_model}/1/'\n",
    "model = IDS(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = parameters_to_ndarrays(tensors)\n",
    "params_dict = zip(model.state_dict().keys(), weights)\n",
    "state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'fc' in name:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = loggers.TensorBoardLogger(save_dir=args['save_dir'],) \n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        filename='{epoch:02d}-{val_loss:.2f}-{val_f1:.4f}',\n",
    "        every_n_epochs=args['val_freq'],\n",
    "        monitor='val_loss', \n",
    "        save_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim1/miniconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:448: LightningDeprecationWarning: Setting `Trainer(gpus=[0])` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=[0])` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=args['epochs'], accelerator='cuda', \n",
    "                        gpus=[0], logger=logger, log_every_n_steps=100, \n",
    "                        check_val_every_n_epoch=args['val_freq'],\n",
    "                        callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: ../save/FedAvg_FN/Tesla/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | Classifier       | 700 K \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "699 K     Trainable params\n",
      "258       Non-trainable params\n",
      "700 K     Total params\n",
      "2.801     Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/home/dhkim1/miniconda3/envs/torch/lib/python3.7/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a47d55f5504e59a322569842c84a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim1/miniconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.9102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim1/miniconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7614819dcdf34559ac2a335a739d48f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592d598f1a384786ae5eeb915054aad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.9609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905e46265f964a4fa16783da4f2e56d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.9968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ddd1c3ca59418086c7229245483f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.9984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c66b6656f2460bb9374d9d4e1db337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.9985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce54c7096464109bf7c8e16fd244b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1 score: 0.9984\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dhkim1/miniconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1767: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=4)`.\n",
      "  category=PossibleUserWarning,\n",
      "/home/dhkim1/miniconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4af2624da8491ebf88c68ae45a387e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.9993265993265994, 0.00042444821731748726)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_files = '../save/FedAvg_FN/Kia/lightning_logs/version_1/checkpoints/epoch=04-val_loss=0.00-val_f1=0.9994.ckpt'\n",
    "fedavg_model = IDS.load_from_checkpoint(ckpt_files, **args)\n",
    "test_model(args['data_dir'], fedavg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::empty_strided' with arguments from the 'MPS' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty_strided' is only available for these backends: [Dense, FPGA, Conjugate, Negative, ZeroTensor, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nCPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterCPU.cpp:37386 [kernel]\nCUDA: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterCUDA.cpp:51977 [kernel]\nMeta: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterMeta.cpp:31637 [kernel]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1294 [kernel]\nQuantizedCUDA: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterQuantizedCUDA.cpp:546 [kernel]\nBackendSelect: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/ConjugateFallback.cpp:22 [kernel]\nNegative: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nTracer: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/TraceType_2.cpp:14069 [kernel]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ebab9389d7a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mckpt_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../save/Kia/lightning_logs/version_1/checkpoints/epoch=49-val_loss=0.00-val_f1=0.9992.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlocal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mhparams_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         )\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpl_legacy_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhparams_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/pytorch_lightning/utilities/cloud_io.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_rebuild_device_tensor_from_numpy\u001b[0;34m(data, dtype, device, requires_grad)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_rebuild_device_tensor_from_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::empty_strided' with arguments from the 'MPS' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty_strided' is only available for these backends: [Dense, FPGA, Conjugate, Negative, ZeroTensor, UNKNOWN_TENSOR_TYPE_ID, QuantizedXPU, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseCPU, SparseCUDA, SparseHIP, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, SparseXPU, UNKNOWN_TENSOR_TYPE_ID, SparseVE, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, NestedTensorCUDA, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID, UNKNOWN_TENSOR_TYPE_ID].\n\nCPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterCPU.cpp:37386 [kernel]\nCUDA: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterCUDA.cpp:51977 [kernel]\nMeta: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterMeta.cpp:31637 [kernel]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1294 [kernel]\nQuantizedCUDA: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterQuantizedCUDA.cpp:546 [kernel]\nBackendSelect: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/build/aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/core/PythonFallbackKernel.cpp:133 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/ConjugateFallback.cpp:22 [kernel]\nNegative: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nZeroTensor: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/ZeroTensorFallback.cpp:90 [kernel]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradIPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/VariableType_2.cpp:14214 [autograd kernel]\nTracer: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/autograd/generated/TraceType_2.cpp:14069 [kernel]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/autocast_mode.cpp:481 [backend fallback]\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:89 [backend fallback]\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1659484772347/work/aten/src/ATen/core/PythonFallbackKernel.cpp:137 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "ckpt_files = '../save/Kia/lightning_logs/version_1/checkpoints/epoch=49-val_loss=0.00-val_f1=0.9992.ckpt'\n",
    "local_model = IDS.load_from_checkpoint(ckpt_files, C=2)\n",
    "test_model(args['data_dir'], local_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec8a7a313ab33d199c8aa698bb86bd912b8385ce4922a6e184e3f5edd5eb95f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
