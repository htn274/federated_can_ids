{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "484d0c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "NVIDIA GeForce RTX 2080 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3472c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292980, 447)\n"
     ]
    }
   ],
   "source": [
    "Concatnated = pd.read_csv('Concatnated.csv')    #.set_index('Time')\n",
    "Concatnated = np.array(Concatnated[:292980], dtype=np.float32)\n",
    "#Concatnated = torch.from_numpy(Concatnated)\n",
    "print(Concatnated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a1b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CreatData = []\n",
    "X = Concatnated[:, :446]\n",
    "y = Concatnated[:,446]\n",
    "strat_time = 0\n",
    "timestamp = 10\n",
    "length = len(Concatnated)\n",
    "\n",
    "for i in range(int(abs(length/10-1))):\n",
    "    features = X[strat_time:timestamp, :446]\n",
    "    features = np.reshape(features, (1, 10, 446))\n",
    "    CreatData.append((features, y[timestamp]))\n",
    "\n",
    "    strat_time = strat_time + 10\n",
    "    timestamp = timestamp + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd47f7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Sequences:  23437\n",
      "Number of Testing Sequences:  5860\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = train_test_split(CreatData, test_size=0.2)\n",
    "print(\"Number of Training Sequences: \", len(train_dataset))\n",
    "print(\"Number of Testing Sequences: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40de75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dc9e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 128, kernel_size = 3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 64*1*110, out_features = 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 84)\n",
    "        self.out = nn.Linear(in_features = 84, out_features = 4)                   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        x = x.view(x.size(0), -1)           \n",
    "        x = F.relu(self.fc1(x))               \n",
    "        x = F.relu(self.fc2(x))               \n",
    "        x = self.out(x)                      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60296427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([128, 1, 3, 3])\n",
      "conv1.bias \t\t torch.Size([128])\n",
      "conv2.weight \t\t torch.Size([64, 128, 3, 3])\n",
      "conv2.bias \t\t torch.Size([64])\n",
      "fc1.weight \t\t torch.Size([120, 7040])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([84, 120])\n",
      "fc2.bias \t\t torch.Size([84])\n",
      "out.weight \t\t torch.Size([4, 84])\n",
      "out.bias \t\t torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for name, param in ConvNet().named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6a127c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, mode, path, patience=3, delta=0):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError(\"Argument mode must be one of 'min' or 'max'.\")\n",
    "        if patience <= 0:\n",
    "            raise ValueError(\"Argument patience must be a postive integer.\")\n",
    "        if delta < 0:\n",
    "            raise ValueError(\"Argument delta must not be a negative number.\")\n",
    "            \n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.best_score = np.inf if mode == 'min' else -np.inf\n",
    "        self.counter = 0\n",
    "        \n",
    "    def _is_improvement(self, val_score):\n",
    "        \"\"\"Return True iff val_score is better than self.best_score.\"\"\"\n",
    "        if self.mode == 'max' and val_score > self.best_score + self.delta:\n",
    "            return True\n",
    "        elif self.mode == 'min' and val_score < self.best_score - self.delta:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def __call__(self, val_score, model):\n",
    "        \"\"\"Return True iff self.counter >= self.patience.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self._is_improvement(val_score):\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            print('Val loss improved. Saved model.')\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f'Early stopping counter: {self.counter}/{self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                print(f'Stopped early. Best val loss: {self.best_score:.4f}')\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b12f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, device, criterion):\n",
    "    \"\"\"Train model for one epoch and return the mean train_loss.\"\"\"\n",
    "    model.train()\n",
    "    running_loss_train = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss_train += loss.item()\n",
    "    train_loss = running_loss_train / len(train_loader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85d02d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, device, criterion):\n",
    "    \"\"\"Validate model and return the accuracy and mean loss.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    running_loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            running_loss_val += loss.item()\n",
    "    val_acc = correct / len(valid_loader.dataset)\n",
    "    val_loss = running_loss_val / len(valid_loader.dataset)\n",
    "    return val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba466275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, valid_loader, learning_rate, num_epochs):\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    es = EarlyStopping(mode='min', path='./EarlyStop.pth', patience=5)\n",
    "    model = model.to(device)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.1)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device, criterion)\n",
    "        val_acc, val_loss = validate(model, valid_loader, device, criterion)\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch:2}/{num_epochs}',\n",
    "              f'train loss: {train_loss:.4f}',\n",
    "              f'val loss: {val_loss:.4f}',\n",
    "              f'val acc: {val_acc:.2%}',\n",
    "              sep=' | '\n",
    "             )\n",
    "        if es(val_loss, model):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afd92729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/5 | train loss: 26910.2105 | val loss: 349.1643 | val acc: 81.67%\n",
      "Val loss improved. Saved model.\n",
      "Epoch  2/5 | train loss: 71.4176 | val loss: 287.5189 | val acc: 85.61%\n",
      "Val loss improved. Saved model.\n",
      "Epoch  3/5 | train loss: 42.9539 | val loss: 296.1462 | val acc: 86.77%\n",
      "Early stopping counter: 1/5\n",
      "Epoch  4/5 | train loss: 40.0021 | val loss: 297.2329 | val acc: 86.72%\n",
      "Early stopping counter: 2/5\n",
      "Epoch  5/5 | train loss: 39.6532 | val loss: 297.3329 | val acc: 86.71%\n",
      "Early stopping counter: 3/5\n",
      "Total training time: 48.04467511177063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 64\n",
    "VALID_BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = False\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "valid_loader = torch.utils.data.DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "start = time.time()\n",
    "fit(model, train_loader, valid_loader, learning_rate=LEARNING_RATE, num_epochs=NUM_EPOCHS)\n",
    "print(f'Total training time: {time.time() - start}')\n",
    "model.load_state_dict(torch.load('EarlyStop.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45376d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e4bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
